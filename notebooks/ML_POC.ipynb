{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4eeb69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service as EdgeService\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "from selenium.webdriver.common.by import By  \n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import xlsxwriter\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd15b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_links(url):\n",
    "    \n",
    "    parent = driver.find_element(By.CLASS_NAME, \"flex.sm\\\\:block.gap-4\")\n",
    "    child_element = parent.find_element(By.TAG_NAME, \"a\")\n",
    "    try:\n",
    "        link = child_element.get_attribute(\"href\")\n",
    "    except:\n",
    "        link = \"a/A/A/A/NONE/NONE/NONE/NONE\"\n",
    "    brand, model = link.split('/')[5:7]\n",
    "    a = brand\n",
    "    b = model\n",
    "    print(a, b)\n",
    "    \n",
    "    truc = []\n",
    "    c = 0\n",
    "    while c<5:\n",
    "        photos = driver.find_elements(By.CLASS_NAME, \"img.basis-80.w-80.sm\\\\:w-full.h-50.text-center.relative.loading\")\n",
    "        print(len(photos))\n",
    "\n",
    "        for photo in photos:\n",
    "            phot = photo.find_element(By.CLASS_NAME, \"w-full.object-cover.h-50\")\n",
    "            phot = phot.get_attribute(\"src\")\n",
    "            truc.append(phot)\n",
    "        print(\"got links\")\n",
    "        pgsv = driver.find_element(By.CLASS_NAME, \"pgsuiv\")\n",
    "        pgsv = pgsv.find_element(By.TAG_NAME, \"a\")\n",
    "        print(\"got next page\")\n",
    "        try:\n",
    "            element = driver.find_element(By.CSS_SELECTOR, \"a.relative.inline-flex.items-center.border.border-gray-300.bg-white.px-3.5.py-3.5.text-sm.font-medium.hover:bg-gray-50.focus:z-20.cursor-pointer\")\n",
    "            driver.execute_script(\"arguments[0].click();\", element)\n",
    "        except:\n",
    "            nv_url = url + \"?p=\" + str(c+1)\n",
    "            driver.get(nv_url)\n",
    "        print(\"next page\")\n",
    "        c+=1\n",
    "            \n",
    "    i=0\n",
    "    for link in truc:\n",
    "        # Téléchargez et enregistrez chaque image dans le dossier \"car_images\"\n",
    "        file_name = f\"{a}-{b}-{i+1}.jpg\"\n",
    "        save_path = os.path.join(\"cars_project\", file_name)\n",
    "        download_image(link, save_path)\n",
    "        sys.stdout.write(f\"\\rDownloaded {i+1}/{len(truc)} images\")\n",
    "        i+=1\n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "def download_image(url, save_path):\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                file.write(chunk)\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: unable to download image from {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87bf64e4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver créé\n",
      "dacia sandero\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "Downloaded 125/125 images\n",
      "Done!\n",
      "Driver créé\n",
      "citroen c3\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "Downloaded 125/125 images\n",
      "Done!\n",
      "Driver créé\n",
      "peugeot 2008\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "Downloaded 125/125 images\n",
      "Done!\n",
      "Driver créé\n",
      "renault captur\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "Downloaded 125/125 images\n",
      "Done!\n",
      "Driver créé\n",
      "peugeot 3008\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "Downloaded 125/125 images\n",
      "Done!\n",
      "Driver créé\n",
      "toyota yaris\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "Downloaded 125/125 images\n",
      "Done!\n",
      "Driver créé\n",
      "citroen c4\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "Downloaded 125/125 images\n",
      "Done!\n",
      "Driver créé\n",
      "volkswagen golf\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "Downloaded 125/125 images\n",
      "Done!\n",
      "Driver créé\n",
      "renault megane\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "Downloaded 125/125 images\n",
      "Done!\n",
      "Driver créé\n",
      "ford fiesta\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "Downloaded 125/125 images\n",
      "Done!\n",
      "Driver créé\n",
      "peugeot 308\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "Downloaded 125/125 images\n",
      "Done!\n",
      "Driver créé\n",
      "renault twingo\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "Downloaded 125/125 images\n",
      "Done!\n",
      "Driver créé\n",
      "volkswagen polo\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "25\n",
      "got links\n",
      "got next page\n",
      "next page\n",
      "Downloaded 125/125 images\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Edge()\n",
    "\n",
    "liste_url = [\n",
    "    \"https://www.paruvendu.fr/a/voiture-occasion/peugeot/208/\",\n",
    "    \"https://www.paruvendu.fr/a/voiture-occasion/renault/clio/\",\n",
    "    \"https://www.paruvendu.fr/a/voiture-occasion/dacia/sandero/\",\n",
    "    \"https://www.paruvendu.fr/a/voiture-occasion/citroen/c3/\",\n",
    "    \"https://www.paruvendu.fr/a/voiture-occasion/peugeot/2008/\",\n",
    "    \"https://www.paruvendu.fr/a/voiture-occasion/renault/captur/\",\n",
    "    \"https://www.paruvendu.fr/a/voiture-occasion/peugeot/3008/\",\n",
    "    \"https://www.paruvendu.fr/a/voiture-occasion/toyota/yaris/\",\n",
    "    \"https://www.paruvendu.fr/a/voiture-occasion/citroen/c4/\",\n",
    "    \"https://www.paruvendu.fr/a/voiture-occasion/volkswagen/golf/\",\n",
    "    \"https://www.paruvendu.fr/a/voiture-occasion/renault/megane/\",\n",
    "    \"https://www.paruvendu.fr/a/voiture-occasion/ford/fiesta/\",\n",
    "    \"https://www.paruvendu.fr/a/voiture-occasion/peugeot/308/\",\n",
    "    \"https://www.paruvendu.fr/a/voiture-occasion/renault/twingo/\",\n",
    "    \"https://www.paruvendu.fr/a/voiture-occasion/volkswagen/polo/\"\n",
    "]\n",
    "\n",
    "nb_model = 1\n",
    "for url in liste_url:\n",
    "    driver.get(url)\n",
    "    liste = pd.DataFrame()\n",
    "    print(\"Driver créé\")\n",
    "    \n",
    "    if nb_model == 1:\n",
    "        cookie = driver.find_element(By.XPATH, \"//button[@onclick='cmp_pv.cookie.saveConsent(true);']\")\n",
    "        cookie.click()\n",
    "\n",
    "    os.makedirs(\"cars_project\", exist_ok=True)\n",
    "\n",
    "    extract_image_links(url)\n",
    "    nb_model+=1\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea27e4",
   "metadata": {},
   "source": [
    "## Preprocessing et modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3b0c9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1456 validated image filenames belonging to 15 classes.\n",
      "Found 365 validated image filenames belonging to 15 classes.\n",
      "Epoch 1/35\n",
      "46/46 [==============================] - 195s 4s/step - loss: 4.6944 - accuracy: 0.0742 - val_loss: 2.6572 - val_accuracy: 0.0959\n",
      "Epoch 2/35\n",
      "46/46 [==============================] - 196s 4s/step - loss: 2.6698 - accuracy: 0.0790 - val_loss: 2.6202 - val_accuracy: 0.0904\n",
      "Epoch 3/35\n",
      "46/46 [==============================] - 222s 5s/step - loss: 2.6404 - accuracy: 0.1058 - val_loss: 2.6031 - val_accuracy: 0.1014\n",
      "Epoch 4/35\n",
      "46/46 [==============================] - 293s 6s/step - loss: 2.6275 - accuracy: 0.1010 - val_loss: 2.5832 - val_accuracy: 0.1123\n",
      "Epoch 5/35\n",
      "46/46 [==============================] - 324s 7s/step - loss: 2.5998 - accuracy: 0.1174 - val_loss: 2.5645 - val_accuracy: 0.1288\n",
      "Epoch 6/35\n",
      "46/46 [==============================] - 357s 8s/step - loss: 2.5657 - accuracy: 0.1291 - val_loss: 2.5508 - val_accuracy: 0.1342\n",
      "Epoch 7/35\n",
      "46/46 [==============================] - 315s 7s/step - loss: 2.5257 - accuracy: 0.1394 - val_loss: 2.5373 - val_accuracy: 0.1671\n",
      "Epoch 8/35\n",
      "46/46 [==============================] - 304s 7s/step - loss: 2.4756 - accuracy: 0.1889 - val_loss: 2.5066 - val_accuracy: 0.1808\n",
      "Epoch 9/35\n",
      "46/46 [==============================] - 278s 6s/step - loss: 2.4180 - accuracy: 0.2157 - val_loss: 2.4689 - val_accuracy: 0.2110\n",
      "Epoch 10/35\n",
      "46/46 [==============================] - 253s 5s/step - loss: 2.3990 - accuracy: 0.2122 - val_loss: 2.4380 - val_accuracy: 0.1973\n",
      "Epoch 11/35\n",
      " 6/46 [==>...........................] - ETA: 7:19:11 - loss: 2.3214 - accuracy: 0.2614"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 96\u001b[0m\n\u001b[0;32m     93\u001b[0m train_generator\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m     94\u001b[0m validation_generator\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m---> 96\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Save the model (optional)\u001b[39;00m\n\u001b[0;32m    105\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcar_model_classifier.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the directory and parameters\n",
    "data_dir = r'C:\\Users\\user\\Documents\\cars_project'\n",
    "img_width, img_height = 480, 360\n",
    "batch_size = 32\n",
    "epochs = 35\n",
    "\n",
    "# Load filenames and extract labels\n",
    "filenames = os.listdir(data_dir)\n",
    "labels = [filename.split('-')[:2] for filename in filenames]\n",
    "labels = pd.DataFrame(labels, columns=['brand', 'model'])\n",
    "labels['filename'] = filenames\n",
    "\n",
    "\n",
    "# Kmeans \n",
    "\n",
    "k = 15\n",
    "kmeans = KMeans(n_clusters = k, random_state=42)\n",
    "kmeans.fit(filenames)\n",
    "\n",
    "labels = kmeans.labels_\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "#End of Kmeans\n",
    "\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_filenames, val_filenames, train_labels, val_labels = train_test_split(\n",
    "    labels['filename'], labels['model'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create data generators for training and validation sets\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=labels.loc[labels['filename'].isin(train_filenames)],\n",
    "    directory=data_dir,\n",
    "    x_col='filename',\n",
    "    y_col='model',\n",
    "    color_mode = 'grayscale',\n",
    "    target_size=(img_width, img_height),\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe=labels.loc[labels['filename'].isin(val_filenames)],\n",
    "    directory=data_dir,\n",
    "    x_col='filename',\n",
    "    y_col='model',\n",
    "    color_mode = 'grayscale',\n",
    "    target_size=(img_width, img_height),\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Get the number of unique car models (classes)\n",
    "num_classes = len(labels['model'].unique())\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create a label binarizer for one-hot encoding\n",
    "label_binarizer = LabelBinarizer()\n",
    "train_labels_one_hot = label_binarizer.fit_transform(train_labels)\n",
    "val_labels_one_hot = label_binarizer.transform(val_labels)\n",
    "\n",
    "# Train the model using fit with custom data generators\n",
    "train_generator.reset()\n",
    "validation_generator.reset()\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "\n",
    "# Save the model (optional)\n",
    "model.save('car_model_classifier.h5')\n",
    "\n",
    "# Save the label binarizer (to be used during prediction)\n",
    "with open('label_binarizer.pkl', 'wb') as f:\n",
    "    pickle.dump(label_binarizer, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ef67dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predicted car model: 2008\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "\n",
    "with open('label_binarizer.pkl', 'rb') as f:\n",
    "    label_binarizer = pickle.load(f)\n",
    "\n",
    "# Replace 'path_to_your_image.jpg' with the actual path to the image you want to predict\n",
    "img_path = r\"C:\\Users\\user\\Documents\\cars_project\\peugeot-2008-85.jpg\"\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = image.load_img(img_path, target_size=(250, 190), color_mode = 'grayscale')\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "# Make a prediction\n",
    "predictions = model.predict(x)\n",
    "\n",
    "# Get the index of the predicted class\n",
    "predicted_class_idx = np.argmax(predictions[0])\n",
    "\n",
    "# Get the predicted car model\n",
    "predicted_model = label_binarizer.classes_[predicted_class_idx]\n",
    "\n",
    "print(f\"Predicted car model: {predicted_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054e8590",
   "metadata": {},
   "source": [
    "# Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0f9e566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car rectangles: [array([  0,  89, 662, 297])]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "thres = 0.50  # Threshold to detect objects\n",
    "\n",
    "# Load class names from coco.names file\n",
    "classNames = []\n",
    "classFile = 'coco.names'\n",
    "with open(classFile, 'rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "# Load the pre-trained model\n",
    "configPath = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "weightsPath = 'frozen_inference_graph.pb'\n",
    "\n",
    "net = cv2.dnn_DetectionModel(weightsPath, configPath)\n",
    "net.setInputSize(320, 320)\n",
    "net.setInputScale(1.0 / 127.5)\n",
    "net.setInputMean((127.5, 127.5, 127.5))\n",
    "net.setInputSwapRB(True)\n",
    "\n",
    "def detect_cars(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Check if the image is loaded successfully\n",
    "    if img is None:\n",
    "        print(\"Error: Image not found or invalid image path.\")\n",
    "        return [], None\n",
    "\n",
    "    img = cv2.resize(img, (700, 500))\n",
    "\n",
    "    classIds, confs, bbox = net.detect(img, confThreshold=thres)\n",
    "\n",
    "    car_rectangles = []\n",
    "\n",
    "    if len(classIds) != 0:\n",
    "        for classId, confidence, box in zip(classIds.flatten(), confs.flatten(), bbox):\n",
    "            # Ensure classId is within the valid range and corresponds to a car\n",
    "            if 0 <= classId < len(classNames) and classNames[classId - 1].lower() == 'car':\n",
    "                car_rectangles.append(box)\n",
    "                cv2.rectangle(img, box, color=(0, 255, 0), thickness=2)\n",
    "                cv2.putText(img, classNames[classId - 1].upper(), (box[0] + 10, box[1] + 30),\n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.putText(img, str(round(confidence * 100, 2)), (box[0] + 200, box[1] + 30),\n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "            else:\n",
    "                print(f\"Invalid classId: {classId}\")\n",
    "\n",
    "    return car_rectangles, img\n",
    "\n",
    "# Replace 'path_to_your_image.jpg' with the actual path to the image you want to detect cars in\n",
    "image_path = r\"C:\\Users\\user\\Documents\\cars_project\\peugeot-2008-8.jpg\"\n",
    "car_rectangles, img = detect_cars(image_path)\n",
    "print(\"Car rectangles:\", car_rectangles)\n",
    "\n",
    "# Display the image with detected objects\n",
    "cv2.imshow('Image with Detected Cars', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23af7eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
